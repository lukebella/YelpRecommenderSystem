{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !git clone https://github.com/lukebella/YelpRecommenderSystem.git\n",
    "    !mv YelpRecommenderSystem/* .\n",
    "    !rm -fr YelpRecommenderSystem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxxxxx\"\n",
    "!kaggle datasets download -p ./data -d yelp-dataset/yelp-dataset\n",
    "!unzip -n ./data/yelp-dataset.zip -d ./data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_filename = 'data/yelp_academic_dataset_review.json'\n",
    "user_filename = 'data/yelp_academic_dataset_user.json'\n",
    "business_filename = 'data/yelp_academic_dataset_business.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# .master().config('spark.driver.memory', \"15g\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# sc = pyspark.SparkContext().getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add docstring\n",
    "def from_json_to_RDD(filename):\n",
    "    raw_df = spark.read.json(filename)\n",
    "    # raw_df.printSchema()\n",
    "    raw_df.show()\n",
    "    return raw_df.rdd\n",
    "\n",
    "raw_review_RDD = from_json_to_RDD(review_filename)\n",
    "raw_user_RDD = from_json_to_RDD(user_filename)\n",
    "raw_business_RDD = from_json_to_RDD(business_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RETRIEVE RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO ADD REPARTITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_tuple(entry):\n",
    "    \"\"\" Parse a row in the review dataset form pyspark.sql.Row to tuple\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the review dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (review_id, user_id, business_id, stars, useful, funny, cool, text)\n",
    "    \"\"\"\n",
    "\n",
    "    return (str(entry[\"review_id\"]),    # 0\n",
    "            str(entry[\"user_id\"]),      # 1\n",
    "            str(entry[\"business_id\"]),  # 2\n",
    "            int(entry[\"stars\"]),        # 3\n",
    "            int(entry[\"useful\"]),       # 4\n",
    "            int(entry[\"funny\"]),        # 5\n",
    "            int(entry[\"cool\"]),         # 6\n",
    "            str(entry[\"text\"]))         # 7\n",
    "\n",
    "\n",
    "review_RDD = raw_review_RDD.map(get_review_tuple)\n",
    "\n",
    "review_count = review_RDD.count()\n",
    "\n",
    "print(f'There are {review_count} reviews in the dataset')\n",
    "print(f'Reviews: {review_RDD.first()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tuple(entry):\n",
    "    \"\"\" Parse a row in the user dataset form pyspark.sql.Row to tuple\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the user dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (user_id, name, review_count, average_stars, useful, funny, cool, fans)\n",
    "    \"\"\"\n",
    "\n",
    "    return (str(entry[\"user_id\"]),          # 0\n",
    "            str(entry[\"name\"]),             # 1\n",
    "            int(entry[\"review_count\"]),     # 2\n",
    "            float(entry[\"average_stars\"]),  # 3\n",
    "            int(entry[\"useful\"]),           # 4\n",
    "            int(entry[\"funny\"]),            # 5\n",
    "            int(entry[\"cool\"]),             # 6\n",
    "            int(entry[\"fans\"]))             # 7\n",
    "\n",
    "\n",
    "user_RDD = raw_user_RDD.map(get_user_tuple)\n",
    "\n",
    "user_count = user_RDD.count()\n",
    "\n",
    "print(f'There are {user_count} users in the dataset')\n",
    "print(f'Users: {user_RDD.first()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_tuple(entry):\n",
    "    \"\"\" Parse a row in the business dataset form pyspark.sql.Row to tuple\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the business dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (business_id, name, city, state, stars, review_count, categories)\n",
    "    \"\"\"\n",
    "\n",
    "    categories = [] if entry[\"categories\"] == None \\\n",
    "                    else str(entry[\"categories\"]).split(\", \")\n",
    "    \n",
    "    return (str(entry[\"business_id\"]),  # 0\n",
    "            str(entry[\"name\"]),         # 1\n",
    "            str(entry[\"city\"]),         # 2\n",
    "            str(entry[\"state\"]),        # 3\n",
    "            float(entry[\"stars\"]),      # 4\n",
    "            int(entry[\"review_count\"]), # 5\n",
    "            categories)                 # 6\n",
    "\n",
    "#TODO Attributes?\n",
    "\n",
    "business_RDD = raw_business_RDD.map(get_business_tuple)\n",
    "\n",
    "business_count = business_RDD.count()\n",
    "\n",
    "print(f'There are {business_count} business in the dataset')\n",
    "print(f'Business: {business_RDD.first()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate overall\n",
    "\n",
    "$$\n",
    "  \\Delta = \\dfrac{1}{2} \n",
    "              \\left( \n",
    "                  \\dfrac{\\text{useful} + \\dfrac{1}{2}(\\text{funny} + \\text{cool})} \n",
    "                        {\\text{best\\ useful} + \\dfrac{1}{2}(\\text{best\\ funny} + \\text{best\\ cool})}\n",
    "                        + \n",
    "                  \\dfrac{\\text{fans}}\n",
    "                        {\\text{best\\ fans}}\n",
    "              \\right)\n",
    "$$\n",
    "$$\n",
    "\\Delta : [0, 1]\n",
    "$$\n",
    "$$\n",
    "  \\text{overall} = \\begin{cases} \n",
    "              \\text{stars} + \\Delta & \\text{if stars } \\ge 3\\\\ \n",
    "              \\text{stars} - \\Delta & \\text{if stars } \\lt 3\n",
    "            \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix all comment\n",
    "\n",
    "#review_RDD.filter(lambda x: x[3]==0).count()\n",
    "\n",
    "\n",
    "#stars - useful - funny - cool - numero fan\n",
    "\n",
    "\n",
    "#if stars <3\n",
    "    #stars - {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fan/best user fans)}/2\n",
    "#else\n",
    "    #stars + {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fan/best user fans)}/2\n",
    "\n",
    "    #dati mancanti: numero fan; best fan; best useful/funny/cool per ristorante\n",
    "#rdd_test_ufc = (id ristorsante, best useful, best funny, best cool)\n",
    "#best fan = query su dataset utenti --> user_RDD.max().first()\n",
    "\n",
    "#review_id - user_id - id_rist - overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_overall_rating: function that generates the bias in order to incentivate or decrease the importance or overall rating of a review\n",
    "\n",
    "# TODO fix function\n",
    "\n",
    "#+ (fans/best_user_fans)) / 2\n",
    "\n",
    "# def get_overall_rating(stars, best_useful, best_funny, best_cool, useful, funny, cool):\n",
    "#     overall = (useful + (funny + cool)/2) / (best_useful + (best_funny + best_cool)/2) \n",
    "#     if stars < 3:\n",
    "#         return stars - overall\n",
    "#     else:\n",
    "#         return stars + overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_best_ufc_RDD tuple: (business_id, (useful, funny, cool)): for each reastaurant, this tuple takes the maxima values of useful, funny and cool. \n",
    "review_best_ufc_RDD = review_RDD.map(lambda x : (x[2], (x[4], x[5], x[6]))).reduceByKey(lambda x, y : tuple(max(x[i], y[i]) for i in range(len(y))))\n",
    "\n",
    "# TODO split map and reduce\n",
    "# review_best_ufc_RDD.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add map to turn the result in a simple tuple\n",
    "\n",
    "# (id_business, ((id_review, id_user, star, useful, funny , cool), (best useful, best funny, best cool)))\n",
    "review_ufc_RDD = review_RDD.map(lambda x: (x[2], (x[0], x[1], x[3], x[4], x[5], x[6]))).join(review_best_ufc_RDD)\n",
    "# review_ufc_RDD.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add function / rewrite after map in previous cell\n",
    "\n",
    "partial_review_overall_RDD = review_ufc_RDD.map(lambda x: (x[1][0][0], x[1][0][1], x[0], x[1][0][2], \n",
    "                                                           (x[1][0][3] + (x[1][0][4] + x[1][0][5])/2) / (x[1][1][0] + (x[1][1][1] + x[1][1][2])/2) if sum(x[1][1]) != 0 else 0))\n",
    "# partial_review_overall_RDD.first()\n",
    "\n",
    "# tuple: (review_id, user_id, buisness_id, stars, partial overall) \n",
    "\n",
    "# ('A2q7d-CBM2-81tVkmS4JMw',(('RB8UpF_kT2xoOC51OzXEeA', 'EZjT2qJN0mOXypMAqZdSrQ', 2, 1, 1, 0),(21, 13, 18)))\n",
    "\n",
    "#if(best_useful && best_funny && best_cool !=0 )\n",
    "# {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fans/best user fans)}/2\n",
    "\n",
    "# x = 10 if sum(x[1][1]) != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple: (user_id, fans)\n",
    "user_fans_RDD = user_RDD.map(lambda x: (x[0], x[7]))\n",
    "\n",
    "# TODO add map to turn the result in a simple tuple\n",
    "# tuple: (user_id, (review_id, buisness_id, stars, partial overall), fans)\n",
    "partial_overall_fans_RDD = partial_review_overall_RDD.map(lambda x: (x[1], (x[0], x[2], x[3], x[4]))).join(user_fans_RDD)\n",
    "\n",
    "# partial_overall_fans_RDD.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user with the highest number of fans\n",
    "best_user_fans = user_RDD.max(lambda x: x[7])\n",
    "print(best_user_fans)\n",
    "\n",
    "# TODO if best user fans = 0\n",
    "# TODO add function / rewrite after map in previous cell\n",
    "review_overall_RDD = partial_overall_fans_RDD.map(lambda x: (x[1][0][0], x[0], x[1][0][1], x[1][0][2] + (x[1][0][3]+x[1][1]/best_user_fans[7])/(2 if x[1][0][2] >=3 else -2)))\n",
    "\n",
    "review_overall_RDD.sortBy(lambda x:x[3], ascending=False).take(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_RDD.sortBy(lambda x: x[5], ascending=False).take(10)\n",
    "\n",
    "# business_review_count_mean = business_RDD.map(lambda x: x[5]).stats()\n",
    "# print(business_review_count_mean)\n",
    "# business_RDD.map(lambda x: x[5]).filter(lambda x: x >=15).stats()  #Keeping at least half of the restaurants present in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_by_business_filtered_RDD = review_overall_RDD.map(lambda x: (x[2], (x[0], x[1], x[3]))).groupByKey().mapValues(list).filter(lambda x: len(x[1])>=20)\n",
    "# review_by_business_filtered_RDD.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFunction(tuple):\n",
    "    \"\"\" Construct the sort string (does not perform actual sorting)\n",
    "    Args:\n",
    "        tuple: (rating, MovieName)\n",
    "    Returns:\n",
    "        sortString: the value to sort with, 'rating MovieName'\n",
    "    \"\"\"\n",
    "    #key = unicode('%.3f' % tuple[0])\n",
    "    if (tuple[1][1]!= None):\n",
    "        value = '{:.3f}'.format(tuple[1][1])\n",
    "    else:\n",
    "        value = ''\n",
    "    key = tuple[0]\n",
    "    return (value + ' ' + key)\n",
    "\n",
    "\n",
    "business_overall_RDD = review_by_business_filtered_RDD.map(lambda x: (x[0],  sum(i[2] for i in x[1])/len(x[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top reccomended business\n",
    "# business_RDD.map(lambda x: (x[0], (x[1], x[6]))).leftOuterJoin(business_overall_RDD).sortBy(sortFunction, False).take(10)  #x[2], x[3],.filter(lambda x: 'Restaurants' in x[1][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO in the collaborative prt, take into consideration the categories and the State\n",
    "#TODO based on the number of reviews, multiply by the percentage of the reviews made in a particular state (same for the categories)\n",
    "# print(dict(sorted(business_RDD.flatMap(lambda x: tuple(x[6])).countByValue().items(), key=lambda x: x[1], reverse=True))) lista delle categorie piÃ¹ frequenti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Because the differences in the quality of items and the rating scales of users are\n",
    "# such important factors in determining the missing elements of the matrix M , it\n",
    "# is often useful to remove these influences before doing anything else. The idea\n",
    "# was introduced in Section 9.3.1. We can subtract from each nonblank element\n",
    "# mij the average rating of user i. Then, the resulting matrix can be modified\n",
    "# by subtracting the average rating (in the modified matrix) of item j. It is also\n",
    "# possible to first subtract the average rating of item j and then subtract the\n",
    "# average rating of user i in the modified matrix. The results one obtains from\n",
    "# doing things in these two different orders need not be the same, but will tend\n",
    "# to be close. A third option is to normalize by subtracting from mij the average\n",
    "# of the average rating of user i and item j, that is, subtracting one half the sum\n",
    "# of the user average and the item average.\n",
    "# If we choose to normalize M , then when we make predictions, we need to\n",
    "# undo the normalization. That is, if whatever prediction method we use results\n",
    "# in estimate e for an element mij of the normalized matrix, then the value\n",
    "# we predict for mij in the true utility matrix is e plus whatever amount was\n",
    "# subtracted from row i and from column j during the normalization process.\n",
    "\n",
    "#review_overall_RDD.flatMap(lambda x : ((x[1], x[2]), 1)).reduceByKey(lambda x, y : x + y).sortBy(lambda x: x[1], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media voti utente\n",
    "average_user_RDD = review_overall_RDD.map(lambda x: (x[1], x[3])).reduceByKey(lambda x,y: (x+y)/2)\n",
    "# average_user_RDD.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media voti business\n",
    "average_business_RDD = review_overall_RDD.map(lambda x: (x[2], x[3])).reduceByKey(lambda x,y: (x+y)/2)\n",
    "# average_business_RDD.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge review rates with average user\n",
    "partial_normalized_RDD = review_overall_RDD.map(lambda x: (x[1], (x[2], x[3]))).join(average_user_RDD).map(lambda x: (x[0], x[1][0][0], x[1][0][1], x[1][1]))\n",
    "# partial_normalized_RDD.take(10)\n",
    "\n",
    "# tuple: (user_id, buisness_id, overall, average_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_RDD = partial_normalized_RDD.map(lambda x: (x[1], (x[0], x[2], x[3]))) \\\n",
    "                                       .join(average_business_RDD) \\\n",
    "                                       .map(lambda x: ((x[1][0][0], x[0]), (x[1][0][1] - (x[1][1]+x[1][0][2])/2))) \\\n",
    "                                       .reduceByKey(lambda x, y : (x+y)/2) \\\n",
    "                                       .map(lambda x: (*x[0], x[1]))\n",
    "\n",
    "normalized_RDD.first()\n",
    "# tuple: (user_id, buisness_id, overall - normalized_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to train and predict the vectors U and V\n",
    "# train(trainingRDD, rank, iterations, regularization_parameter)  --> (U,V)\n",
    "#We need to calculate RMSE between the utility and our matrix\n",
    "\n",
    "rank = 2\n",
    "iterations = 5\n",
    "# regularization_parameter = 0.1\n",
    "\n",
    "# U_RDD = user_RDD.map(lambda x: (x[0], [1 for _ in range(rank)])).sortBy(lambda x: x[0])\n",
    "# V_RDD = business_RDD.map(lambda x: (x[0], [1 for _ in range(rank)])).sortBy(lambda x: x[0])\n",
    "\n",
    "# U_RDD.take(5)\n",
    "# V_RDD.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_RDD = normalized_RDD.map(lambda x: (x[0], (x[1], x[2]))).groupByKey().mapValues(list).map(lambda x : (x[0], [1 for _ in range(rank)], x[1]))\n",
    "U_RDD.first()\n",
    "\n",
    "# tuple: (id_user, [1, ... ,1], [reviews])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_RDD = normalized_RDD.map(lambda x: (x[1], (x[0], x[2]))).groupByKey().mapValues(list).map(lambda x : (x[0], [1 for _ in range(rank)], x[1]))\n",
    "V_RDD.first()\n",
    "\n",
    "# tuple: (id_business, [1, ... ,1], [reviews])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (non-blank - (U x V))^2 + ...\n",
    "\n",
    "# CV : \n",
    "# for (iter):\n",
    "#     calc U\n",
    "#     calc V\n",
    "# RMSE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_BC = sc.broadcast(dict(V_RDD.map(lambda x : (x[0], x[1])).collect()))\n",
    "\n",
    "V_BC.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_BC = sc.broadcast(dict(U_RDD.map(lambda x : (x[0], x[1])).collect()))\n",
    "\n",
    "U_BC.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_U(entry):\n",
    "    id = entry[0]\n",
    "    U_value = entry[1]\n",
    "    reviews = entry[2] # normalized\n",
    "\n",
    "    # out = [1]*rank\n",
    "    for s in range(rank):\n",
    "        res = 0\n",
    "        den = 0\n",
    "        for review in reviews:\n",
    "            j = review[0] # business_id\n",
    "            p = 0\n",
    "            for k in [i for i in range(rank) if i != s]:\n",
    "                p += U_value[k] * V_BC.value[j][k]\n",
    "\n",
    "            res += V_BC.value[j][s] * (review[1] - p)\n",
    "            den += V_BC.value[j][s]**2\n",
    "        U_value[s] = res / (den if den > 0 else 1)\n",
    "\n",
    "    return (id, U_value)\n",
    "\n",
    "\n",
    "U_RDD.map(lambda x :  update_U(x)).take(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
