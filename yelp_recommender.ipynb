{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Aggiungere cella per diminuire calcoli (e dimensione dataset?)\n",
    "- Creare un RDD i cui elementi siano le coppie righe/colonne e con un'operazione di map/reduce emettere coppie chiave-valore nelle quali la chiave indica la posizione (i, j) dell'elemento della matrice da aggiornare e il valore indica il nuovo elemento della matrice, utilizzando le formule del paragrafo 9.4.4. In questo modo \"parallelizzate\" gli aggiornamenti di tutti gli elementi della matrice. Eventualmente potete evitare di aggiornare d'un colpo tutta la matrice (potrebbe portare a difficoltà nella convergenza), decidendo in modo probabilistico ogni volta se aggiornare oppure no un elemento: basta che il job map/reduce generi un bit pseudocasuale che vale 1 con probabilità p, e se il suo valore è 1 allora utilizzate le formule di cui sopra, altrimenti restituite il valore attuale di U (fa parte della colonna che ottenete in input). In questo modo aggiornerete all'incirca una frazione pari a p dei valori della matrice. Lo stesso vale per V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !pip install pyspark\n",
    "    !git clone https://github.com/lukebella/YelpRecommenderSystem.git\n",
    "    !mv YelpRecommenderSystem/* .\n",
    "    !rm -fr YelpRecommenderSystem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: kaggle\n",
      "unzip:  cannot find or open ./data/yelp-dataset.zip, ./data/yelp-dataset.zip.zip or ./data/yelp-dataset.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxxxxx\"\n",
    "!kaggle datasets download -p ./data -d yelp-dataset/yelp-dataset\n",
    "!unzip -n ./data/yelp-dataset.zip -d ./data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_filename = 'data/yelp_academic_dataset_review.json'\n",
    "user_filename = 'data/yelp_academic_dataset_user.json'\n",
    "business_filename = 'data/yelp_academic_dataset_business.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lavorare su un sample più piccolo (10%)\n",
    "### conviente farlo solo sulle review per problemi di join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# .master().config('spark.driver.memory', \"15g\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# sc = pyspark.SparkContext().getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|XQfwVwDr-v0ZS3_Cb...|   0|2018-07-07 22:09:11|    0|KU_O5udG6zpxOg-Vc...|  3.0|If you decide to ...|     0|mh_-eMZ6K5RLWhZyI...|\n",
      "|7ATYjTIgM3jUlt4UM...|   1|2012-01-03 15:28:18|    0|BiTunyQ73aT9WBnpR...|  5.0|I've taken a lot ...|     1|OyoGAe7OKpv6SyGZT...|\n",
      "|YjUWPpI6HXG530lwP...|   0|2014-02-05 20:30:30|    0|saUsX_uimxRlCVr67...|  3.0|Family diner. Had...|     0|8g_iMtfSiwikVnbP2...|\n",
      "|kxX2SOes4o-D3ZQBk...|   1|2015-01-04 00:01:03|    0|AqPFMleE6RsU23_au...|  5.0|Wow!  Yummy, diff...|     1|_7bHUi9Uuf5__HHc_...|\n",
      "|e4Vwtrqf-wpJfwesg...|   1|2017-01-14 20:54:15|    0|Sx8TMOWLNuJBWer-0...|  4.0|Cute interior and...|     1|bcjbaE6dDog4jkNY9...|\n",
      "|04UD14gamNjLY0IDY...|   1|2015-09-23 23:10:31|    2|JrIxlS1TzJ-iCu79u...|  1.0|I am a long term ...|     1|eUta8W_HdHMXPzLBB...|\n",
      "|gmjsEdUsKpj9Xxu6p...|   0|2015-01-03 23:21:18|    2|6AxgBCNX_PNTOxmbR...|  5.0|Loved this tour! ...|     0|r3zeYsv1XFBRA4dJp...|\n",
      "|LHSTtnW3YHCeUkRDG...|   0|2015-08-07 02:29:16|    0|_ZeMknuYdlQcUqng_...|  5.0|Amazingly amazing...|     2|yfFzsLmaWF2d4Sr0U...|\n",
      "|B5XSoSG3SfvQGtKEG...|   0|2016-03-30 22:46:33|    1|ZKvDG2sBvHVdF5oBN...|  3.0|This easter inste...|     1|wSTuiTk-sKNdcFypr...|\n",
      "|gebiRewfieSdtt17P...|   0|2016-07-25 07:31:06|    0|pUycOfUwM8vqX7KjR...|  3.0|Had a party of 6 ...|     0|59MxRhNVhU9MYndMk...|\n",
      "|uMvVYRgGNXf5boolA...|   0|2015-06-21 14:48:06|    0|rGQRf8UafX7OTlMNN...|  5.0|My experience wit...|     2|1WHRWwQmZOZDAhp2Q...|\n",
      "|EQ-TZ2eeD_E0BHuvo...|   0|2015-08-19 14:31:45|    0|l3Wk_mvAog6XANIuG...|  4.0|Locals recommende...|     0|ZbqSHbgCjzVAqaa7N...|\n",
      "|lj-E32x9_FA7GmUrB...|   0|2014-06-27 22:44:01|    0|XW_LfMv0fV21l9c6x...|  4.0|Love going here f...|     0|9OAtfnWag-ajVxRbU...|\n",
      "|RZtGWDLCAtuipwaZ-...|   0|2009-10-14 19:57:14|    0|8JFGBuHMoiNDyfcxu...|  4.0|Good food--loved ...|     0|smOvOajNG0lS4Pq7d...|\n",
      "|otQS34_MymijPTdNB...|   0|2011-10-27 17:12:05|    2|UBp0zWyH60Hmw6Fsa...|  4.0|The bun makes the...|     0|4Uh27DgGzsp6PqrH9...|\n",
      "|BVndHaLihEYbr76Z0...|   0|2014-10-11 16:22:06|    0|OAhBYw8IQ6wlfw1ow...|  5.0|Great place for b...|     0|1C2lxzUo1Hyye4RFI...|\n",
      "|YtSqYv1Q_pOltsVPS...|   0|2013-06-24 11:21:25|    0|oyaMhzBSwfGgemSGu...|  5.0|Tremendous servic...|     0|Dd1jQj7S-BFGqRbAp...|\n",
      "|rBdG_23USc7DletfZ...|   0|2014-08-10 19:41:43|    0|LnGZB0fjfgeVDVz5I...|  4.0|The hubby and I h...|     1|j2wlzrntrbKwyOcOi...|\n",
      "|CLEWowfkj-wKYJlQD...|   1|2016-03-07 00:02:18|    0|u2vzZaOqJ2feRshaa...|  5.0|I go to blow bar ...|     2|NDZvyYHTUWWu-kqgQ...|\n",
      "|eFvzHawVJofxSnD7T...|   0|2014-11-12 15:30:27|    0|Xs8Z8lmKkosqW5mw_...|  5.0|My absolute favor...|     0|IQsF3Rc6IgCzjVV9D...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+---------+------------+------+--------------------+-------------------+\n",
      "|average_stars|compliment_cool|compliment_cute|compliment_funny|compliment_hot|compliment_list|compliment_more|compliment_note|compliment_photos|compliment_plain|compliment_profile|compliment_writer| cool|               elite|fans|             friends|funny|     name|review_count|useful|             user_id|      yelping_since|\n",
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+---------+------------+------+--------------------+-------------------+\n",
      "|         3.91|            467|             56|             467|           250|             18|             65|            232|              180|             844|                55|              239| 5994|                2007| 267|NSCy54eWehBJyZdG2...| 1259|   Walker|         585|  7217|qVc8ODYU5SZjKXVBg...|2007-01-25 16:47:26|\n",
      "|         3.74|           3131|            157|            3131|          1145|            251|            264|           1847|             1946|            7054|               184|             1521|27281|2009,2010,2011,20...|3138|ueRPE0CX75ePGMqOF...|13066|   Daniel|        4333| 43091|j14WgRoU_-2ZE1aw1...|2009-01-25 04:35:42|\n",
      "|         3.32|            119|             17|             119|            89|              3|             13|             66|               18|              96|                10|               35| 1003|2009,2010,2011,20...|  52|LuO3Bn4f3rlhyHIaN...| 1010|    Steph|         665|  2086|2WnXYQFK0hXEoTxPt...|2008-07-25 10:41:00|\n",
      "|         4.27|             26|              6|              26|            24|              2|              4|             12|                9|              16|                 1|               10|  299|      2009,2010,2011|  28|enx1vVPnfdNUdPho6...|  330|     Gwen|         224|   512|SZDeASXq7o05mMNLs...|2005-11-29 04:38:33|\n",
      "|         3.54|              0|              0|               0|             1|              0|              1|              1|                0|               1|                 0|                0|    7|                    |   1|PBK4q9KEEBHhFvSXC...|   15|    Karen|          79|    29|hA5lMy-EnncsH4JoR...|2007-01-05 19:40:59|\n",
      "|         3.85|           2543|            361|            2543|          1713|            147|            163|           1212|              323|            5696|               191|              815|11211|2006,2007,2008,20...|1357|xBDpTUbai0DXrvxCe...| 9940|     Jane|        1221| 14953|q_QQ5kBBwlCcbL1s4...|2005-03-14 20:26:35|\n",
      "|         2.75|              0|              0|               0|             0|              0|              0|              0|                0|               1|                 0|                0|    0|                    |   1|HDAQ74AEznP-YsMk1...|    1|      Rob|          12|     6|cxuxXkcihfCbqt5By...|2009-02-24 03:09:06|\n",
      "|         3.73|             12|              0|              12|             4|              0|              7|              8|                0|               6|                 2|                5|  143|                    |  23|y2GyxJF5VQWohxgw_...|  102|     Mike|         358|   399|E9kcWJdJUHuTKfQur...|2008-12-11 22:11:56|\n",
      "|         4.04|              5|              3|               5|             2|              0|              0|              3|                1|               4|                 0|                3|   46|                    |   7|tOQDlz36rI__SOsbL...|   40| Rachelle|          40|   109|lO1iq-f75hnPNZkTy...|2008-12-29 22:40:56|\n",
      "|          3.4|              3|              0|               3|             0|              0|              0|              1|                0|               6|                 0|                0|   23|                    |   4|gy5fWeSv3Gamuq9Ox...|   20|     John|         109|   154|AUi8MPWJ0mLkMfwbu...|2010-01-07 18:32:04|\n",
      "|          4.0|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|    1|                    |   1|Vq4Pc81l6MWTnc-h4...|    0|    Chris|           4|     1|iYzhPPqnrjJkg1JHZ...|2010-11-03 18:59:20|\n",
      "|         3.89|             36|              3|              36|            23|              5|              9|             31|                7|              41|                 1|               24|  573| 2009,2010,2011,2012|  31|6tbXpUIU6upoeqWND...|  487|     Ryan|         535|  1130|xoZvMJPDW6Q9pDAXI...|2009-05-27 06:12:10|\n",
      "|         4.51|              0|              0|               0|             4|              0|              0|              1|                0|               5|                 0|                1|   27|                    |   4|zkK6c9BcDyqreU0fq...|    3| Charlene|          37|    63|vVukUtqoLF5BvH_Vt...|2011-01-29 17:18:59|\n",
      "|         3.08|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|    0|                    |   0|f0mdrhyxVZ0TsFZD5...|    3|    Kenny|          11|    30|_crIokUeTCHVK_JVO...|2009-10-07 17:23:44|\n",
      "|         4.29|              2|              0|               2|             1|              0|              0|              1|                0|               0|                 0|                0|   13|                    |   1|piejMEdRkGB7-1aL4...|    3|   Teresa|           7|    18|1McG5Rn_UDkmlkZOr...|2009-05-26 16:11:11|\n",
      "|         3.75|            221|             22|             221|           212|             34|             17|             67|               17|             158|                17|               45| 1297|2007,2008,2009,20...|  44|j3MBGSLaXMlhLZNeA...| 1138|   Eugene|         682|  1819|SgiBkhXeqIKl1PlFp...|2006-08-25 16:47:25|\n",
      "|         4.15|              2|              0|               2|             0|              0|              1|              6|                0|               2|                 0|                1|   19|                    |   1|hJiJzw6obCmbGAfwr...|    2| Jennifer|          25|    29|fJZO_skqpnhk1kvom...|2008-07-14 16:01:36|\n",
      "|         3.84|             66|              0|              66|            15|              0|              1|             12|               12|              33|                 0|                1|   29|                    |   9|EPBLDry-ObheloH-N...|   29|  Ronskee|          37|    56|x7YtLnBW2dUnrrpwa...|2010-05-06 00:40:56|\n",
      "|         4.11|            808|             29|             808|          1020|             23|             79|            144|              723|             407|                68|              587| 4149|2010,2011,2012,20...| 131|dLts9bY66tXEFqYG0...| 3714|Catherine|         607|  4573|QF1Kuhs8iwLWANNZx...|2009-04-27 20:25:54|\n",
      "|          3.6|              0|              0|               0|             1|              0|              0|              2|                0|               4|                 0|                1|   44|                    |   4|Ynu2Z2L8Wv2fbTwQ_...|   52|       AJ|         133|   201|VcLRGCG_VbAo8MxOm...|2009-07-11 16:47:38|\n",
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+---------+------------+------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+-------------+--------------+--------------------+-----------+------------+-----+-----+\n",
      "|             address|          attributes|         business_id|          categories|          city|               hours|is_open|     latitude|     longitude|                name|postal_code|review_count|stars|state|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+-------------+--------------+--------------------+-----------+------------+-----+-----+\n",
      "|1616 Chapala St, ...|{null, null, null...|Pns2l4eNsfO8kk83d...|Doctors, Traditio...| Santa Barbara|                null|      0|   34.4266787|  -119.7111968|Abby Rappoport, L...|      93101|           7|  5.0|   CA|\n",
      "|87 Grasso Plaza S...|{null, null, null...|mpf3x-BjTdTEA3yCZ...|Shipping Centers,...|        Affton|{8:0-18:30, 0:0-0...|      1|    38.551126|    -90.335695|       The UPS Store|      63123|          15|  3.0|   MO|\n",
      "|5255 E Broadway Blvd|{null, null, null...|tUFrWirKiKi_TAnsV...|Department Stores...|        Tucson|{8:0-23:0, 8:0-22...|      0|    32.223236|   -110.880452|              Target|      85711|          22|  3.5|   AZ|\n",
      "|         935 Race St|{null, null, u'no...|MTSW4McQd7CbVtyjq...|Restaurants, Food...|  Philadelphia|{7:0-21:0, 7:0-20...|      1|   39.9555052|   -75.1555641|  St Honore Pastries|      19107|          80|  4.0|   PA|\n",
      "|       101 Walnut St|{null, null, null...|mWMc6_wTdE0EUBKIG...|Brewpubs, Breweri...|    Green Lane|{12:0-22:0, null,...|      1|   40.3381827|   -75.4716585|Perkiomen Valley ...|      18054|          13|  4.5|   PA|\n",
      "|       615 S Main St|{null, null, u'no...|CF33F8-E6oudUQ46H...|Burgers, Fast Foo...|  Ashland City|{9:0-0:0, 0:0-0:0...|      1|    36.269593|    -87.058943|      Sonic Drive-In|      37015|           6|  2.0|   TN|\n",
      "|8522 Eager Road, ...|{null, null, null...|n_0UpQx1hsNbnPUSl...|Sporting Goods, F...|     Brentwood|{10:0-18:0, 0:0-0...|      1|    38.627695|    -90.340465|     Famous Footwear|      63144|          13|  2.5|   MO|\n",
      "|  400 Pasadena Ave S|                null|qkRM_2X51Yqxk3btl...|Synagogues, Relig...|St. Petersburg|{9:0-17:0, 9:0-17...|      1|     27.76659|    -82.732983|      Temple Beth-El|      33707|           5|  3.5|   FL|\n",
      "|   8025 Mackenzie Rd|{null, null, u'fu...|k0hlBqXX-Bt0vf1op...|Pubs, Restaurants...|        Affton|                null|      0|   38.5651648|   -90.3210868|Tsevi's Pub And G...|      63123|          19|  3.0|   MO|\n",
      "| 2312 Dickerson Pike|{null, null, u'no...|bBDDEgkFA1Otx9Lfe...|Ice Cream & Froze...|     Nashville|{6:0-16:0, 0:0-0:...|      1|   36.2081024|   -86.7681696|      Sonic Drive-In|      37207|          10|  1.5|   TN|\n",
      "|21705 Village Lak...|{null, null, null...|UJsufbvfyfONHeWdv...|Department Stores...| Land O' Lakes|{9:30-21:30, 9:30...|      1|28.1904587953|-82.4573802199|           Marshalls|      34639|           6|  3.5|   FL|\n",
      "|                    |{null, null, 'non...|eEOYSgkmpB90uNA7l...|Vietnamese, Food,...|     Tampa Bay|{11:0-14:0, 11:0-...|      1|   27.9552692|   -82.4563199|Vietnamese Food T...|      33602|          10|  4.0|   FL|\n",
      "|        8901 US 31 S|{null, null, 'non...|il_Ro8jwPlHresjw9...|American (Traditi...|  Indianapolis|{6:0-22:0, 6:0-22...|      1|39.6371332838| -86.127217412|             Denny's|      46227|          28|  2.5|   IN|\n",
      "|   15 N Missouri Ave|{null, null, null...|jaxMSoInw8Poo3XeM...|General Dentistry...|    Clearwater|{null, 7:30-15:30...|      1|    27.966235|    -82.787412|        Adams Dental|      33755|          10|  5.0|   FL|\n",
      "|       2575 E Bay Dr|{null, null, u'no...|0bPLkL0QhhPO5kt1_...|Food, Delis, Ital...|         Largo|{10:0-20:0, 10:0-...|      0|   27.9161159|   -82.7604608|Zio's Italian Market|      33771|         100|  4.5|   FL|\n",
      "|         205 Race St|{null, null, 'ful...|MUTTqe8uqyMdBl186...|Sushi Bars, Resta...|  Philadelphia|{13:30-23:0, null...|      1|    39.953949|   -75.1432262|            Tuna Bar|      19106|         245|  4.0|   PA|\n",
      "|     625 N Stone Ave|{null, null, null...|rBmpy_Y1UbBx8ggHl...|Automotive, Auto ...|        Tucson|{8:0-17:0, 0:0-0:...|      1|   32.2298719|  -110.9723419|Arizona Truck Out...|      85705|          10|  4.5|   AZ|\n",
      "|        712 Adams St|{null, null, null...|M0XSSHqrASOnhgbWD...|Vape Shops, Tobac...|   New Orleans|{10:0-19:0, 10:0-...|      1|29.9414679565| -90.129952757|      Herb Import Co|      70118|           5|  4.0|   LA|\n",
      "|     1241 Airline Dr|                null|8wGISYjYkE2tSqn3c...|Automotive, Car R...|        Kenner|{8:0-17:0, 8:0-17...|      1|    29.981183|   -90.2540123|    Nifty Car Rental|      70062|          14|  3.5|   LA|\n",
      "|       1224 South St|{null, null, u'no...|ROeacJQwBeh05Rqg7...| Korean, Restaurants|  Philadelphia|{11:30-20:30, 11:...|      1|    39.943223|    -75.162568|                 BAP|      19147|         205|  4.5|   PA|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+-------------+--------------+--------------------+-----------+------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(business_id='XQfwVwDr-v0ZS3_CbbE5Xw', cool=0, date='2018-07-07 22:09:11', funny=0, review_id='KU_O5udG6zpxOg-VcAEodg', stars=3.0, text=\"If you decide to eat here, just be aware it is going to take about 2 hours from beginning to end. We have tried it multiple times, because I want to like it! I have been to it's other locations in NJ and never had a bad experience. \\n\\nThe food is good, but it takes a very long time to come out. The waitstaff is very young, but usually pleasant. We have just had too many experiences where we spent way too long waiting. We usually opt for another diner or restaurant on the weekends, in order to be done quicker.\", useful=0, user_id='mh_-eMZ6K5RLWhZyISBhwA')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO add docstring\n",
    "def from_json_to_RDD(filename):\n",
    "    raw_df = spark.read.json(filename)\n",
    "    raw_df.show()\n",
    "    #return raw_df.sample(frac=1/10, random_state = 0).dropna().rdd\n",
    "    return raw_df.rdd\n",
    "\n",
    "raw_review_RDD = from_json_to_RDD(review_filename)#.sample(True, 1, 0)  #699192 rows #shuffle\n",
    "raw_user_RDD = from_json_to_RDD(user_filename)\n",
    "raw_business_RDD = from_json_to_RDD(business_filename)\n",
    "#print(raw_business_RDD.filter(lambda x: x[2]=='bqFG0QJY9jj2m55OqAVHeA').first())\n",
    "\n",
    "raw_review_RDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve RDD 60 with partitions 0\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13608"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample number of users and take all the reviews made by the users in the subset\n",
    "#TODO that not all the users taken have made a review, we could try to eliminate those who have not made a review? \n",
    "# Those users should see the starting recommendation...\n",
    "# print(raw_user_RDD.count())\n",
    "raw_user_RDD_bis = raw_user_RDD.filter(lambda x:x[-4]>0).sample(False, 1/500, 0) #withReplacement of .sample True or False?\n",
    "user_list = raw_user_RDD_bis.map(lambda x: x[-2]).collect()\n",
    "#3295\n",
    "raw_review_RDD = raw_review_RDD.filter(lambda x: (x[8] in user_list))\n",
    "print(len(user_list))\n",
    "raw_review_RDD.count()\n",
    "#11444\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RETRIEVE RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash(s):\n",
    "    h = hashlib.sha1(s.encode())\n",
    "    return int(h.hexdigest(),16)%((2**31)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:======================================================> (39 + 1) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13608 reviews in the dataset\n",
      "Reviews: (77151601, 444249529, 1016675114, 4, 0, 0, 0, '4-5 stars, this is just after one visit so far, worth a try if you\\'re a thai fan. I liked the food, but you always have to have the first visit to see \"how they do things\" and figure out what your preferences will need to be.\\n\\nI did use their living social deal so I brought my dad in when he came in from out of town to try it out with me. I like the set up, the quaint house is cute (and well, quaint), but I can see how it wouldn\\'t be ideal it if was jam packed. I imagine you could potentially do family style for some of the pub height tabletops. I did call ahead to make sure that I didn\\'t need to print out the coupon and it could be used from my ipod and to make sure they were open, as the website said to just double check.\\n\\nWe started with shrimp spring rolls, probably the best I\\'ve had, the ingredients seemed fresher, and crispier. No shredded lettuce here. Simple and loosely wrapped, but you could taste the individual components. The peanut sauce was tasty too, though they don\\'t have sirracha (spelling?) to add to it, just dried pepper flakes. \\n\\nWe then got the tom yum (gai?) with shrimp. I know it is hot (because of the name, duh), I usually prefer it a little less spicy (I am white), though I still got a good sour flavor (for instance at Thai chili it\\'s too hot for me, I don\\'t taste any sour). I usually get my tom yum without meat or seafood because I feel the meat gets dried out, but the server assured me the shrimp wouldn\\'t be overcooked, and they weren\\'t. I think they are making sure to use fresh ingredients, but I do prefer straw mushrooms (I think they are usually canned) over the button mushrooms they used. Next time I am probably going to try out a veggie version (i love the soup with the cabbage, and broccoli). The owner did tell me they are trying to be authentic and so maybe button mushrooms and less veggies is more authentic?\\n\\nWe then got shrimp pad thai and chicken pad keo mao (drunken noodle) minus the red pepper. Both were tasty, the portions were probably a little less than other places in Reno (not sure if just lunch sized portion now that I think about it).\\n\\nLike Ernie said, the pad thai noodles were a little soft, overdone, and its not the \\'orange-y\\' sauce like other pad thai\\'s, but there was still flavor there. The shrimp were also tasty in this dish. The drunken noodles was done exactly how I like them, lots of baby corns and the noodles covered in the sauce and of course spicy. \\n\\nMy dad and I talked outside for a while and the husband did come out and talk with me about the food, and asked if I was happy (we were outside a while). I hope the living social deals bring in some business, and I do plan on coming back, it is just hard because I don\\'t live in the area. I also asked about the cooking classes (they are a steal at $65), and on facebook it said they are looking to improve and give some focus to that side of the business. The owner did say that they use just a regular kitchen so no woks or anything like that (meaning what they teach us can actually be done at home), I wonder if that is why the pad thai noodles are that way? Regardless, they seem to pride themselves on authentic and quality food and service.\\n\\nI did include pictures. Oh I did try a thai iced tea for the first time too, pretty tasty, reminded me of chai tea. \\n\\nI didn\\'t get to see the bill closely, but it was $24 and some change after the living social deal (takes $20 off), I didn\\'t think that was too bad for 2 for lunch (the total cost), with an appetizer and soup and a drink.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_review_tuple(entry):\n",
    "    \"\"\" Parse a row in the review dataset form pyspark.sql.Row to tuple (remove unintersted columns)\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the review dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (review_id, user_id, business_id, stars, useful, funny, cool, text)\n",
    "    \"\"\"\n",
    "\n",
    "    return (hash(str(entry[\"review_id\"])),    # 0\n",
    "            hash(str(entry[\"user_id\"])),      # 1\n",
    "            hash(str(entry[\"business_id\"])),  # 2\n",
    "            int(entry[\"stars\"]),        # 3\n",
    "            int(entry[\"useful\"]),       # 4\n",
    "            int(entry[\"funny\"]),        # 5\n",
    "            int(entry[\"cool\"]),         # 6\n",
    "            str(entry[\"text\"]))         # 7\n",
    "\n",
    "\n",
    "review_RDD = raw_review_RDD.map(get_review_tuple)\n",
    "\n",
    "review_count = review_RDD.count()\n",
    "\n",
    "print(f'There are {review_count} reviews in the dataset')\n",
    "print(f'Reviews: {review_RDD.first()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1987897 users in the dataset\n",
      "Users: (1328793112, 'Walker', 585, 3.91, 7217, 1259, 5994, 267)\n"
     ]
    }
   ],
   "source": [
    "def get_user_tuple(entry):\n",
    "    \"\"\" Parse a row in the user dataset form pyspark.sql.Row to tuple (remove unintersted columns)\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the user dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (user_id, name, review_count, average_stars, useful, funny, cool, fans)\n",
    "    \"\"\"\n",
    "\n",
    "    return (hash(str(entry[\"user_id\"])),          # 0\n",
    "            str(entry[\"name\"]),             # 1\n",
    "            int(entry[\"review_count\"]),     # 2\n",
    "            float(entry[\"average_stars\"]),  # 3\n",
    "            int(entry[\"useful\"]),           # 4\n",
    "            int(entry[\"funny\"]),            # 5\n",
    "            int(entry[\"cool\"]),             # 6\n",
    "            int(entry[\"fans\"]))             # 7\n",
    "\n",
    "\n",
    "user_RDD = raw_user_RDD.map(get_user_tuple)\n",
    "\n",
    "user_count = user_RDD.count()\n",
    "\n",
    "print(f'There are {user_count} users in the dataset')\n",
    "print(f'Users: {user_RDD.first()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 150346 business in the dataset\n",
      "Business: (1768608060, 'Abby Rappoport, LAC, CMQ', 'Santa Barbara', 'CA', 5.0, 7, ['Doctors', 'Traditional Chinese Medicine', 'Naturopathic/Holistic', 'Acupuncture', 'Health & Medical', 'Nutritionists'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_business_tuple(entry):\n",
    "    \"\"\" Parse a row in the business dataset form pyspark.sql.Row to tuple (remove unintersted columns)\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the business dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (business_id, name, city, state, stars, review_count, categories)\n",
    "    \"\"\"\n",
    "\n",
    "    categories = [] if entry[\"categories\"] == None \\\n",
    "                    else str(entry[\"categories\"]).split(\", \")\n",
    "    \n",
    "    return (hash(str(entry[\"business_id\"])),  # 0\n",
    "            str(entry[\"name\"]),         # 1\n",
    "            str(entry[\"city\"]),         # 2\n",
    "            str(entry[\"state\"]),        # 3\n",
    "            float(entry[\"stars\"]),      # 4\n",
    "            int(entry[\"review_count\"]), # 5\n",
    "            categories)                 # 6\n",
    "\n",
    "#TODO Attributes?\n",
    "\n",
    "business_RDD = raw_business_RDD.map(get_business_tuple)\n",
    "\n",
    "business_count = business_RDD.count()\n",
    "# print(business_RDD.filter(lambda x: x[0]=='1H8ReY5GlGcHJz7umVidkg').first())\n",
    "\n",
    "print(f'There are {business_count} business in the dataset')\n",
    "print(f'Business: {business_RDD.first()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate overall\n",
    "### - for each business_id:\n",
    "\n",
    "$$\n",
    "  \\Delta = \\dfrac{1}{2} \n",
    "              \\left( \n",
    "                  \\dfrac{\\text{useful} + \\dfrac{1}{2}(\\text{funny} + \\text{cool})} \n",
    "                        {\\text{best\\ useful} + \\dfrac{1}{2}(\\text{best\\ funny} + \\text{best\\ cool})}\n",
    "                        + \n",
    "                  \\dfrac{\\text{fans}}\n",
    "                        {\\text{best\\ fans}}\n",
    "              \\right)\n",
    "$$\n",
    "$$\n",
    "\\Delta : [0, 1]\n",
    "$$\n",
    "$$\n",
    "  \\text{overall} = \\begin{cases} \n",
    "              \\text{stars} + \\Delta & \\text{if stars } \\ge 3\\\\ \n",
    "              \\text{stars} - \\Delta & \\text{if stars } \\lt 3\n",
    "            \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix all comment\n",
    "\n",
    "#review_RDD.filter(lambda x: x[3]==0).count()\n",
    "\n",
    "\n",
    "#stars - useful - funny - cool - numero fan\n",
    "\n",
    "\n",
    "#if stars <3\n",
    "    #stars - {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fan/best user fans)}/2\n",
    "#else\n",
    "    #stars + {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fan/best user fans)}/2\n",
    "\n",
    "    #dati mancanti: numero fan; best fan; best useful/funny/cool per ristorante\n",
    "#rdd_test_ufc = (id ristorsante, best useful, best funny, best cool)\n",
    "#best fan = query su dataset utenti --> user_RDD.max().first()\n",
    "\n",
    "#review_id - user_id - id_rist - overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_overall_rating: function that generates the bias in order to incentivate or decrease the importance or overall rating of a review\n",
    "\n",
    "# TODO fix function\n",
    "\n",
    "#+ (fans/best_user_fans)) / 2\n",
    "\n",
    "# def get_overall_rating(stars, best_useful, best_funny, best_cool, useful, funny, cool):\n",
    "#     overall = (useful + (funny + cool)/2) / (best_useful + (best_funny + best_cool)/2) \n",
    "#     if stars < 3:\n",
    "#         return stars - overall\n",
    "#     else:\n",
    "#         return stars + overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(94502400, (1, 0, 1)),\n",
       " (491225560, (0, 0, 0)),\n",
       " (1770665880, (0, 0, 0)),\n",
       " (1981417000, (6, 2, 2)),\n",
       " (299406040, (0, 0, 0))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_business_id_useful_funny_cool(row):\n",
    "    \"\"\"\n",
    "        Writes a tuple with key business_id and attributes useful, funny, cool\n",
    "    \"\"\"\n",
    "    return (row[2], (row[4], row[5], row[6]))\n",
    "\n",
    "def get_max_useful_funny_cool(row1, row2):\n",
    "    \"\"\"\n",
    "        Returns a new RDD with, for each business_id key, the maxima values of useful, funny, cool\n",
    "    \"\"\"\n",
    "    return tuple(max(row1[i], row2[i]) for i in range(3))\n",
    "\n",
    "review_tuple_RDD = review_RDD.map(get_business_id_useful_funny_cool)\n",
    "review_best_ufc_RDD = review_tuple_RDD.reduceByKey(get_max_useful_funny_cool)\n",
    "\n",
    "review_best_ufc_RDD.take(5)\n",
    "\n",
    "# review_best_ufc_RDD tuple: (business_id, (useful, funny, cool)): for each reastaurant, this tuple takes the maxima values of useful, funny and cool. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94502400, ((1256229733, 636305136, 5, 0, 0, 0), (1, 0, 1)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rearrange_review_and_best_ufc_RDD(row):\n",
    "    \"\"\"\n",
    "        Merge, for each business_id, the row values with the best useful, funny, cool ones\n",
    "    \"\"\"\n",
    "    return (row[2], (row[0], row[1], row[3], row[4], row[5], row[6]))\n",
    "\n",
    "review_ufc_RDD = review_RDD.map(rearrange_review_and_best_ufc_RDD).join(review_best_ufc_RDD)\n",
    "review_ufc_RDD.first()\n",
    "\n",
    "# (id_business, ((id_review, id_user, star, useful, funny , cool), (best useful, best funny, best cool)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1256229733, 636305136, 94502400, 5, 0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partial_overall(x):\n",
    "    \"\"\"\n",
    "        Rearrange review_ufc_RDD and calculates the partial overall of the delta above\n",
    "        partial_overall ={[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2]\n",
    "    \"\"\"\n",
    "    key = (x[1][0][0], x[1][0][1], x[0], x[1][0][2])\n",
    "    num = (x[1][0][3] + (x[1][0][4] + x[1][0][5])/2)\n",
    "    den = (x[1][1][0] + (x[1][1][1] + x[1][1][2])/2)\n",
    "    return (*key,(num/den if sum(x[1][1]) != 0 else 0))\n",
    "\n",
    "\n",
    "partial_review_overall_RDD = review_ufc_RDD.map(partial_overall)\n",
    "partial_review_overall_RDD.first()\n",
    "\n",
    "# tuple: (review_id, user_id, buisness_id, stars, partial overall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1622563412, ((988434858, 1830274560, 1, 1.0), 0))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple: (user_id, fans)\n",
    "user_fans_RDD = user_RDD.map(lambda x: (x[0], x[7]))\n",
    "\n",
    "# TODO add map to turn the result in a simple tuple\n",
    "# tuple: (user_id, (review_id, buisness_id, stars, partial overall), fans)\n",
    "partial_overall_fans_RDD = partial_review_overall_RDD.map(lambda x: (x[1], (x[0], x[2], x[3], x[4]))).join(user_fans_RDD)\n",
    "\n",
    "partial_overall_fans_RDD.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with the highest number of fans:  (526211061, 'Mike', 1882, 4.39, 22860, 10965, 15350, 12497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1944424370, 1435479599, 1324409120, 5.507921901256301),\n",
       " (1795278908, 1298897066, 690862244, 5.507161718812515),\n",
       " (812528418, 1298897066, 491347608, 5.507161718812515),\n",
       " (490468167, 1298897066, 2087399929, 5.507161718812515),\n",
       " (338941442, 1298897066, 1986851853, 5.507161718812515)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user with the highest number of fans\n",
    "best_user_fans = user_RDD.max(lambda x: x[7])\n",
    "print(\"User with the highest number of fans: \",best_user_fans)\n",
    "\n",
    "# TODO if best user fans = 0\n",
    "\n",
    "def review_overall(x):\n",
    "    user_id, review_id, business_id, stars= x[0], x[1][0][0], x[1][0][1], x[1][0][2]\n",
    "    value = stars + (x[1][0][3]+x[1][1]/best_user_fans[7])/(2 if stars >=3 else -2) \n",
    "    return (review_id, user_id, business_id, value)\n",
    "\n",
    "    #tuple: (review_id, user_id, business_id, stars + (partial overall + fans/best_fans))\n",
    "\n",
    "\n",
    "review_overall_RDD = partial_overall_fans_RDD.map(review_overall)\n",
    "\n",
    "review_overall_RDD.sortBy(lambda x:x[3], ascending=False).take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2102509260,\n",
       "  [(1003713303, 1046582321, 4.139128946502717),\n",
       "   (1828544940, 1994483617, 5.167426849110453),\n",
       "   (1867431700, 1649056566, 5.0),\n",
       "   (590447591, 41026287, 3.0555555555555554),\n",
       "   (1915326982, 398441560, 5.502520604945187),\n",
       "   (586526257, 454274731, 3.1115912263387657),\n",
       "   (260787533, 953966376, 5.000680163239178),\n",
       "   (539915488, 374713485, 5.028097854596214),\n",
       "   (1652614631, 287769425, 5.000080019204609),\n",
       "   (1854456319, 1476814463, 4.000680163239178),\n",
       "   (676273809, 975617949, 5.000200048011523)]),\n",
       " (279921001,\n",
       "  [(810169582, 496957576, 5.001240297671441),\n",
       "   (994433667, 279370217, 4.000080019204609),\n",
       "   (766004812, 739336230, 2.0),\n",
       "   (1834201982, 736911376, 5.0),\n",
       "   (1480686845, 1451210502, 5.000080019204609),\n",
       "   (942708580, 2130554238, 5.000040009602305),\n",
       "   (29282503, 1913891406, 3.0),\n",
       "   (248606800, 158878345, 5.0),\n",
       "   (29852523, 1167756140, 4.001080259262223),\n",
       "   (1960528031, 1494199259, 1.999919980795391),\n",
       "   (299323899, 1133102310, 4.506641593982556),\n",
       "   (1898443501, 699360805, 5.000240057613827),\n",
       "   (978120742, 192982698, 5.000040009602305),\n",
       "   (418483712, 98954763, 4.000040009602305),\n",
       "   (955404487, 1717250617, 5.0),\n",
       "   (1316453414, 843736005, 4.017666906724281),\n",
       "   (537346689, 777786415, 5.051640393694487),\n",
       "   (30234098, 672490075, 5.016906724280494)]),\n",
       " (780097169,\n",
       "  [(1739242286, 617425940, 5.0),\n",
       "   (1797655165, 1372276768, 5.500080019204609),\n",
       "   (1323466928, 670525613, 4.001000240057614),\n",
       "   (1761397105, 513140631, 5.0),\n",
       "   (266214644, 699360805, 5.000240057613827),\n",
       "   (1228936858, 941519502, 1.999919980795391),\n",
       "   (1214438017, 661360442, 5.0),\n",
       "   (1162447473, 856657402, 5.0),\n",
       "   (314247377, 1095839725, 5.000120028806914),\n",
       "   (957938249, 1442282937, 5.000040009602305),\n",
       "   (1597833391, 636923664, 5.000360086420741),\n",
       "   (1618923306, 559563290, 3.0)]),\n",
       " (1066071292,\n",
       "  [(521021275, 1994483617, 3.4174268491104534),\n",
       "   (395479177, 112658411, 4.0),\n",
       "   (1795784270, 41026287, 5.0),\n",
       "   (1850899249, 1964203475, 5.083813448560988),\n",
       "   (2070009561, 82454287, 1.9994398655677363),\n",
       "   (1436630342, 1497900273, 4.000240057613827),\n",
       "   (1388526526, 1497900273, 4.000240057613827),\n",
       "   (1278864289, 763417495, 5.000040009602305),\n",
       "   (340217791, 932269356, 4.250040009602305),\n",
       "   (606481293, 1865110379, 3.0002000480115227)]),\n",
       " (991456304,\n",
       "  [(1667174727, 297816973, 3.0000400096023045),\n",
       "   (1089948480, 1938174411, 4.000080019204609),\n",
       "   (1977938636, 1266220274, 2.0),\n",
       "   (1456216713, 197446662, 5.0),\n",
       "   (1050048569, 521701415, 5.0),\n",
       "   (1309901868, 618033687, 5.0),\n",
       "   (1282059649, 192982698, 5.000040009602305),\n",
       "   (310649692, 1008232838, 5.0),\n",
       "   (1539974063, 843736005, 3.215285954343328),\n",
       "   (467139819, 459172781, 5.0),\n",
       "   (120965605, 1872367440, 5.428691457378342),\n",
       "   (1869136310, 2114910717, 5.0)])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keeping businesses that have at least 10 reviews\n",
    "threshold = 10\n",
    "review_by_business_filtered_RDD = review_overall_RDD.map(lambda x: (x[2], (x[0], x[1], x[3]))).groupByKey()\\\n",
    "                                                    .mapValues(list).filter(lambda x: len(x[1])>=threshold)\n",
    "review_by_business_filtered_RDD.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFunction(tuple):\n",
    "    \"\"\" Construct the sort string (does not perform actual sorting)\n",
    "    Args:\n",
    "        tuple: (rating, MovieName)\n",
    "    Returns:\n",
    "        sortString: the value to sort with, 'rating MovieName'\n",
    "    \"\"\"\n",
    "    #key = unicode('%.3f' % tuple[0])\n",
    "    if (tuple[1][1]!= None):\n",
    "        value = '{:.3f}'.format(tuple[1][1])\n",
    "    else:\n",
    "        value = ''\n",
    "    key = tuple[0]\n",
    "    return (value + ' ' + str(key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2102509260, 4.545996493703944)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make, for each business, the average of the stars for all the reviews\n",
    "\n",
    "business_overall_RDD = review_by_business_filtered_RDD.map(lambda x: (x[0],  sum(i[2] for i in x[1])/len(x[1])))\n",
    "business_overall_RDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(871435685,\n",
       "  ((\"Commander's Palace\",\n",
       "    ['French',\n",
       "     'Restaurants',\n",
       "     'Cocktail Bars',\n",
       "     'Nightlife',\n",
       "     'American (New)',\n",
       "     'Cajun/Creole',\n",
       "     'Breakfast & Brunch',\n",
       "     'American (Traditional)',\n",
       "     'Bars']),\n",
       "   4.778273896846353)),\n",
       " (98911525, (('Los Agaves', ['Mexican', 'Restaurants']), 4.675262917801128)),\n",
       " (1705519317,\n",
       "  ((\"Felix's Restaurant & Oyster Bar\",\n",
       "    ['Restaurants', 'Sandwiches', 'Seafood', 'Cajun/Creole']),\n",
       "   4.6007601824437865)),\n",
       " (615074086,\n",
       "  (('Barbuzzo', ['Mediterranean', 'Restaurants', 'Pizza', 'Italian']),\n",
       "   4.584707406700685)),\n",
       " (2102509260,\n",
       "  (('Reading Terminal Market',\n",
       "    ['Candy Stores',\n",
       "     'Shopping',\n",
       "     'Department Stores',\n",
       "     'Fast Food',\n",
       "     'Beer',\n",
       "     'Wine & Spirits',\n",
       "     'Fruits & Veggies',\n",
       "     'Chinese',\n",
       "     'Food',\n",
       "     'Ice Cream & Frozen Yogurt',\n",
       "     'Desserts',\n",
       "     'Seafood',\n",
       "     'Health Markets',\n",
       "     'Bagels',\n",
       "     'Cheese Shops',\n",
       "     'Shopping Centers',\n",
       "     'Chocolatiers & Shops',\n",
       "     'Meat Shops',\n",
       "     'Public Markets',\n",
       "     'Food Court',\n",
       "     'Wineries',\n",
       "     'Local Flavor',\n",
       "     'Ethnic Food',\n",
       "     'Restaurants',\n",
       "     'Specialty Food',\n",
       "     'Arts & Entertainment',\n",
       "     'Juice Bars & Smoothies',\n",
       "     'Seafood Markets',\n",
       "     'Farmers Market',\n",
       "     'Coffee & Tea',\n",
       "     'Bakeries',\n",
       "     'Food Stands',\n",
       "     'Dinner Theater',\n",
       "     'Sporting Goods',\n",
       "     'Grocery',\n",
       "     'Fashion']),\n",
       "   4.545996493703944)),\n",
       " (780097169,\n",
       "  (('Ruby Slipper - New Orleans',\n",
       "    ['Restaurants',\n",
       "     'American (Traditional)',\n",
       "     'American (New)',\n",
       "     'Cafes',\n",
       "     'Breakfast & Brunch']),\n",
       "   4.541813368541784)),\n",
       " (991456304,\n",
       "  (('Oceana Grill',\n",
       "    ['Restaurants', 'Seafood', 'Cajun/Creole', 'Breakfast & Brunch']),\n",
       "   4.387011454177574)),\n",
       " (279921001,\n",
       "  (('Acme Oyster House',\n",
       "    ['Live/Raw Food', 'Seafood', 'Restaurants', 'Cajun/Creole']),\n",
       "   4.310867571180046)),\n",
       " (1852797739,\n",
       "  ((\"Pappy's Smokehouse\",\n",
       "    ['Food',\n",
       "     'Restaurants',\n",
       "     'Caterers',\n",
       "     'Smokehouse',\n",
       "     'Barbeque',\n",
       "     'Food Trucks',\n",
       "     'Event Planning & Services']),\n",
       "   4.257442929160141)),\n",
       " (174553460,\n",
       "  (('Sushi Rose', ['Sushi Bars', 'Restaurants']), 4.219169637750097))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top recommended businesses\n",
    "business_RDD.map(lambda x: (x[0], (x[1], x[6]))).leftOuterJoin(business_overall_RDD).sortBy(sortFunction, False).take(10)  #x[2], x[3],.filter(lambda x: 'Restaurants' in x[1][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_overall_bis = review_overall_RDD.map(lambda x: (x[1], x[2], x[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Distance\n",
    "def cosine_dist(value):\n",
    "    \"\"\" \n",
    "    arg: utente da confrontare\n",
    "    per ogni utente:\n",
    "        - user_id, prodotto tra rating di item per stessa chiave di item, lista di rating\n",
    "        - somma di valori nel numeratore, somma di liste del denominatore\n",
    "        - prodotto delle somma quadratiche nel denominatore tra i due utenti\n",
    "        - prendi utenti che hanno qualche voto su un business in comune diverso da zero\n",
    "    \"\"\"\n",
    "    value_review = dict(review_overall_bis.filter(lambda x:x[0] == value).map(lambda x:(x[1],x[2])).collect()) #business: voto\n",
    "    print(value_review)\n",
    "    if (len(value_review)==0): \n",
    "        return None, None\n",
    "    user_sim = review_overall_bis.map(lambda x: (x[0], (0 if x[1] not in value_review.keys() \\\n",
    "                                                        else x[2]*value_review[x[1]], [x[2]])))\\\n",
    "                                 .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "                                 .map(lambda x:(x[0], x[1][0]/((sum(i**2 for i in x[1][1])**0.5) * \\\n",
    "                                                               (sum(i**2 for i in value_review.values())**0.5))))\\\n",
    "                                 .filter(lambda x:x[1]!=0 and x[0]!=value).take(5) #prendiamo i 5 utenti più simili\n",
    "    return sorted(user_sim), value_review\n",
    "\n",
    "def collaborative_filtering(value):\n",
    "    #print(value)\n",
    "    user_sim, value_review = cosine_dist(value)\n",
    "    if (user_sim == None and value_review == None):\n",
    "        print(\"Unable to do the Collab Filtering for this user\")\n",
    "        return\n",
    "    #print(value_review.keys())\n",
    "    return review_overall_bis.filter(lambda x: (x[0] in dict(user_sim).keys() and x[1] not in value_review.keys()))\\\n",
    "                             .take(10) #.sortBy(lambda x:x[2],ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:=================================================>    (97 + 8) / 106]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Unable to do the Collab Filtering for this user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# print(review_overall_bis.take(10)[5])\n",
    "business_collab = collaborative_filtering(174553450)\n",
    "# print(review_overall_RDD.filter(lambda x:x[1]=='Eep1pCr1zMqub16tYgUFgQ').collect())\n",
    "business_collab\n",
    "#TODO make print of the business as name, categories..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UV Decompostion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO in the collaborative prt, take into consideration the categories and the State\n",
    "#TODO based on the number of reviews, multiply by the percentage of the reviews made in a particular state (same for the categories)\n",
    "# print(dict(sorted(business_RDD.flatMap(lambda x: tuple(x[6])).countByValue().items(), key=lambda x: x[1], reverse=True))) lista delle categorie più frequenti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to train and predict the vectors U and V\n",
    "# train(trainingRDD, rank, iterations, regularization_parameter)  --> (U,V)\n",
    "#We need to calculate RMSE between the utility and our matrix\n",
    "\n",
    "#TODO initialize U and V with the overall average value\n",
    "\n",
    "rank = 2\n",
    "# regularization_parameter = 0.1\n",
    "\n",
    "U_RDD = user_RDD.map(lambda x: (x[0], [1 for _ in range(rank)]))#.sortBy(lambda x: x[0])\n",
    "V_RDD = business_RDD.map(lambda x: (x[0], [1 for _ in range(rank)]))#.sortBy(lambda x: x[0])\n",
    "\n",
    "# U_RDD.take(5)\n",
    "# V_RDD.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_overall_bis = review_overall_RDD.map(lambda x: (x[1], x[2], x[3]))\n",
    "#review_overall_bis = review_RDD.map(lambda x: (x[1], x[2], x[3]))\n",
    "\n",
    "#print(review_overall_RDD.filter(lambda x: x[1]=='cxuxXkcihfCbqt5Byrup8Q').first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE We are bypassing at the moment the validation set (useful for achieving the best rank)\n",
    "trainingRDD, testRDD = review_overall_bis.randomSplit([7,3], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_BC = sc.broadcast(trainingRDD.collect())\n",
    "\n",
    "# list(filter(lambda x: x[0]=='cxuxXkcihfCbqt5Byrup8Q', M_BC.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo no map\n",
    "# V_BC = sc.broadcast(dict(V_RDD.map(lambda x : (x[0], x[1])).collect()))\n",
    "V_BC = sc.broadcast(dict(V_RDD.collect()))\n",
    "#V_BC.value['KsFuzQCOPhP8eHmt3rP11Q']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo no map\n",
    "# U_BC = sc.broadcast(dict(U_RDD.map(lambda x : (x[0], x[1])).collect()))\n",
    "U_BC = sc.broadcast(dict(U_RDD.collect()))\n",
    "\n",
    "#len(U_BC.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized-->tuple: (user_id, buisness_id, overall - normalized_value)\n",
    "# review_overall --> tuple: (review_id, user_id, business_id, stars + (partial overall + fans/best_fans))\n",
    "#print(business_RDD.filter(lambda x: x[0]=='1H8ReY5GlGcHJz7umVidkg').first())\n",
    "\n",
    "def update_U(entry):\n",
    "    id = entry[0]\n",
    "    U_value = entry[1]\n",
    "    reviews = [i for i in M_BC.value if i[0] == id]\n",
    "    for s in range(rank):\n",
    "        res = 0\n",
    "        den = 0\n",
    "        for review in reviews:\n",
    "            j = review[1] # business_id\n",
    "            p = 0\n",
    "            for k in [i for i in range(rank) if i != s]:\n",
    "                #print(V_BC.value)\n",
    "                \n",
    "                p += U_value[k] * V_BC.value[j][k]\n",
    "\n",
    "            res += V_BC.value[j][s] * (review[2] - p)\n",
    "            den += V_BC.value[j][s]**2\n",
    "        U_value[s] = res / (den if den > 0 else 1)\\\n",
    "            #if len(reviews)>0 else 1\n",
    "\n",
    "    return (id, U_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_V(entry):\n",
    "    id = entry[0]\n",
    "    V_value = entry[1]\n",
    "    reviews = [i for i in M_BC.value if i[1] == id]\n",
    "\n",
    "    # out = [1]*rank\n",
    "    for s in range(rank):\n",
    "        res = 0\n",
    "        den = 0\n",
    "        for review in reviews:\n",
    "            j = review[0] # user_id\n",
    "            p = 0\n",
    "            for k in [i for i in range(rank) if i != s]:\n",
    "                p += V_value[k] * U_BC.value[j][k]\n",
    "\n",
    "            res += U_BC.value[j][s] * (review[2] - p)\n",
    "            den += U_BC.value[j][s]**2\n",
    "        V_value[s] = (res / (den if den > 0 else 1))\\\n",
    "#            if len(reviews)>0 else 1\n",
    "\n",
    "    return (id, V_value)\n",
    "\n",
    "\n",
    "# V_RDD.map(lambda x :  update_V(x)).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(U_RDD,V_RDD,iterations):  \n",
    "# iterations = 2\n",
    "    global V_BC, U_BC\n",
    "    for i in range(iterations):\n",
    "        V_BC = sc.broadcast(dict(V_RDD.collect()))\n",
    "        U_RDD = U_RDD.map(update_U)\n",
    "\n",
    "        U_BC = sc.broadcast(dict(U_RDD.collect()))\n",
    "        V_RDD = V_RDD.map(update_V)\n",
    "\n",
    "    return U_RDD.collect(), V_RDD.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,V = train(U_RDD, V_RDD, iterations =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take an user-id and suggest business that he has not reviewed\n",
    "\n",
    "def predict(u_value, business_value):\n",
    "    return sum(u_value[i]* business_value[i] for i in range(len(u_value)))\n",
    "\n",
    "\n",
    "def print_prediction(username, business_name):\n",
    "\n",
    "    U_dict = dict(U)\n",
    "    V_dict = dict(V)\n",
    "    un = user_RDD.filter(lambda x: x[0]== username).first()[1]\n",
    "    bn = business_RDD.filter(lambda x: x[0]== business_name).first()[2]\n",
    "    print(\"User:\",un, \"----- Business:\",bn, \":\",predict(U_dict[username], V_dict[business_name]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_prediction(\"DEFTCj_6zHCAtwyUvNEBZQ\", \"rBmpy_Y1UbBx8ggHlyb7hA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE of UV Decomposition\n",
    "\n",
    "def rmse(testRDD):\n",
    "    rmse = 0\n",
    "    U_dict = dict(U)\n",
    "    V_dict = dict(V)\n",
    "    for i in testRDD.collect():\n",
    "        rmse += (i[2] - predict(U_dict[i[0]], V_dict[i[1]]))**2\n",
    "    return (rmse/len(M_BC.value))**0.5\n",
    "\n",
    "print(\"RMSE:\", rmse(testRDD))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to populate U and V with the average value of review rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_value = review_overall_bis.map(lambda x: (1, x[2])).reduceByKey(lambda x,y:(x+y)/2).first()[1]\n",
    "avg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_RDD = user_RDD.map(lambda x: (x[0], [avg_value for _ in range(rank)]))#.sortBy(lambda x: x[0])\n",
    "V_RDD = business_RDD.map(lambda x: (x[0], [avg_value for _ in range(rank)]))#.sortBy(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,V = train(U_RDD, V_RDD, iterations =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE of UV Decomposition\n",
    "print(\"RMSE:\", rmse(testRDD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash(s):\n",
    "    h = hashlib.sha1(s.encode())\n",
    "    return int(h.hexdigest(),16)%((2**31)-1)\n",
    "\n",
    "review_overall_tris = review_overall_bis.map(lambda x: (hash(x[0]), hash(x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingRDD, validationRDD, testRDD = review_overall_tris.randomSplit([6, 2, 2], seed=0)\n",
    "\n",
    "print('Training: %s, validation: %s, test: %s\\n' % (trainingRDD.count(),\n",
    "                                                    validationRDD.count(),\n",
    "                                                    testRDD.count()))\n",
    "print(trainingRDD.take(3))\n",
    "print(validationRDD.take(3))\n",
    "print(testRDD.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def computeError(predictedRDD, actualRDD):\n",
    "    \"\"\" Compute the root mean squared error between predicted and actual\n",
    "    Args:\n",
    "        predictedRDD: predicted ratings for each movie and each user where each entry is in the form\n",
    "                      (UserID, MovieID, Rating)\n",
    "        actualRDD: actual ratings where each entry is in the form (UserID, MovieID, Rating)\n",
    "    Returns:\n",
    "        RSME (float): computed RSME value\n",
    "    \"\"\"\n",
    "    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = predictedRDD.map(lambda i: ((i[0], i[1]), i[2]))\n",
    "\n",
    "    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = actualRDD.map(lambda i: ((i[0], i[1]), i[2]))\n",
    "\n",
    "    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n",
    "    # RDD) in the reformatted RDDs using RDD transformtions - do not use collect()\n",
    "    squaredErrorsRDD = (predictedReformattedRDD\n",
    "                        .join(actualReformattedRDD)\n",
    "                        .map(lambda i: math.pow(i[1][0] - i[1][1], 2))\n",
    "                       )\n",
    "\n",
    "    # Compute the total squared error - do not use collect()\n",
    "    totalError = squaredErrorsRDD.reduce(lambda a, b: a+b)\n",
    "\n",
    "    # Count the number of entries for which you computed the total squared error\n",
    "    numRatings = squaredErrorsRDD.count()\n",
    "\n",
    "    # Using the total squared error and the number of entries, compute the RSME\n",
    "    return math.pow(float(totalError) / numRatings, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "validationForPredictRDD = validationRDD.map(lambda i: (i[0], i[1]))\n",
    "\n",
    "seed = 5\n",
    "iterations = 5\n",
    "regularizationParameter = 0.1\n",
    "ranks = [2, 4, 8, 12]\n",
    "errors = [0, 0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "    predictedRatingsRDD = model.predictAll(validationForPredictRDD)\n",
    "    error = computeError(predictedRatingsRDD, validationRDD)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank {} the RMSE is {}'.format(rank, error))\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print('The best model was trained with rank {}'.format(bestRank))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
