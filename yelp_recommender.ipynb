{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !git clone https://github.com/lukebella/YelpRecommenderSystem.git\n",
    "    !mv YelpRecommenderSystem/* .\n",
    "    !rm -fr YelpRecommenderSystem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxxxxx\"\n",
    "!kaggle datasets download -p ./data -d yelp-dataset/yelp-dataset\n",
    "!unzip -n ./data/yelp-dataset.zip -d ./data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_filename = 'data/yelp_academic_dataset_review.json'\n",
    "user_filename = 'data/yelp_academic_dataset_user.json'\n",
    "business_filename = 'data/yelp_academic_dataset_business.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# .master().config('spark.driver.memory', \"15g\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# sc = pyspark.SparkContext().getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add docstring\n",
    "def from_json_to_RDD(filename):\n",
    "    raw_df = spark.read.json(filename)\n",
    "    # raw_df.printSchema()\n",
    "    raw_df.show()\n",
    "    return raw_df.rdd\n",
    "\n",
    "raw_review_RDD = from_json_to_RDD(review_filename)\n",
    "raw_user_RDD = from_json_to_RDD(user_filename)\n",
    "raw_business_RDD = from_json_to_RDD(business_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_tuple(entry):\n",
    "    \"\"\" Parse a row in the review dataset form pyspark.sql.Row to tuple\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the review dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (review_id, user_id, business_id, stars, useful, funny, cool, text)\n",
    "    \"\"\"\n",
    "\n",
    "    return (str(entry[\"review_id\"]),    # 0\n",
    "            str(entry[\"user_id\"]),      # 1\n",
    "            str(entry[\"business_id\"]),  # 2\n",
    "            int(entry[\"stars\"]),        # 3\n",
    "            int(entry[\"useful\"]),       # 4\n",
    "            int(entry[\"funny\"]),        # 5\n",
    "            int(entry[\"cool\"]),         # 6\n",
    "            str(entry[\"text\"]))         # 7\n",
    "\n",
    "\n",
    "review_RDD = raw_review_RDD.map(get_review_tuple)\n",
    "\n",
    "review_count = review_RDD.count()\n",
    "\n",
    "print(f'There are {review_count} reviews in the dataset')\n",
    "print(f'Reviews: {review_RDD.first()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tuple(entry):\n",
    "    \"\"\" Parse a row in the user dataset form pyspark.sql.Row to tuple\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the user dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (user_id, name, review_count, average_stars, useful, funny, cool, fans)\n",
    "    \"\"\"\n",
    "\n",
    "    return (str(entry[\"user_id\"]),          # 0\n",
    "            str(entry[\"name\"]),             # 1\n",
    "            int(entry[\"review_count\"]),     # 2\n",
    "            float(entry[\"average_stars\"]),  # 3\n",
    "            int(entry[\"useful\"]),           # 4\n",
    "            int(entry[\"funny\"]),            # 5\n",
    "            int(entry[\"cool\"]),             # 6\n",
    "            int(entry[\"fans\"]))             # 7\n",
    "\n",
    "\n",
    "user_RDD = raw_user_RDD.map(get_user_tuple)\n",
    "\n",
    "user_count = user_RDD.count()\n",
    "\n",
    "print(f'There are {user_count} users in the dataset')\n",
    "print(f'Users: {user_RDD.first()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_tuple(entry):\n",
    "    \"\"\" Parse a row in the business dataset form pyspark.sql.Row to tuple\n",
    "    Args:\n",
    "        entry (pyspark.sql.types.Row): a row in the business dataset in JSON format\n",
    "    Returns:\n",
    "        tuple: (business_id, name, city, state, stars, review_count, categories)\n",
    "    \"\"\"\n",
    "\n",
    "    categories = [] if entry[\"categories\"] == None \\\n",
    "                    else str(entry[\"categories\"]).split(\", \")\n",
    "    \n",
    "    return (str(entry[\"business_id\"]),  # 0\n",
    "            str(entry[\"name\"]),         # 1\n",
    "            str(entry[\"city\"]),         # 2\n",
    "            str(entry[\"state\"]),        # 3\n",
    "            float(entry[\"stars\"]),      # 4\n",
    "            int(entry[\"review_count\"]), # 5\n",
    "            categories)                 # 6\n",
    "\n",
    "#TODO Attributes?\n",
    "\n",
    "business_RDD = raw_business_RDD.map(get_business_tuple)\n",
    "\n",
    "business_count = business_RDD.count()\n",
    "\n",
    "print(f'There are {business_count} business in the dataset')\n",
    "print(f'Business: {business_RDD.first()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  \\Delta = \\dfrac{1}{2} \n",
    "              \\left( \n",
    "                  \\dfrac{\\text{usefull} + \\dfrac{1}{2}(\\text{funny} + \\text{cool})} \n",
    "                        {\\text{best\\ usefull} + \\dfrac{1}{2}(\\text{best\\ funny} + \\text{best\\ cool})}\n",
    "                        + \n",
    "                  \\dfrac{\\text{fans}}\n",
    "                        {\\text{best\\ fans}}\n",
    "              \\right)\n",
    "$$\n",
    "$$\n",
    "\\Delta : [0, 1]\n",
    "$$\n",
    "$$\n",
    "  \\text{overall} = \\begin{cases} \n",
    "              \\text{stars} + \\Delta & \\text{if stars } \\ge 3\\\\ \n",
    "              \\text{stars} - \\Delta & \\text{if stars } \\lt 3\n",
    "            \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix all comment\n",
    "\n",
    "#review_RDD.filter(lambda x: x[3]==0).count()\n",
    "\n",
    "\n",
    "#stars - useful - funny - cool - numero fan\n",
    "\n",
    "\n",
    "#if stars <3\n",
    "    #stars - {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fan/best user fans)}/2\n",
    "#else\n",
    "    #stars + {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fan/best user fans)}/2\n",
    "\n",
    "    #dati mancanti: numero fan; best fan; best useful/funny/cool per ristorante\n",
    "#rdd_test_ufc = (id ristorsante, best useful, best funny, best cool)\n",
    "#best fan = query su dataset utenti --> user_RDD.max().first()\n",
    "\n",
    "#review_id - user_id - id_rist - overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_overall_rating: function that generates the bias in order to incentivate or decrease the importance or overall rating of a review\n",
    "\n",
    "# TODO fix function\n",
    "\n",
    "# def get_overall_rating(stars, best_useful, best_funny, best_cool, useful, funny, cool, fans):\n",
    "#     overall = ((useful + (funny + cool)/2) / (best_useful + (best_funny + best_cool)/2) + (fans/best_user_fans)) / 2\n",
    "#     if stars < 3:\n",
    "#         return stars - overall\n",
    "#     else:\n",
    "#         return stars + overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_best_ufc_RDD tuple: (business_id, (useful, funny, cool)): for each reastaurant, this tuple takes the maxima values of useful, funny and cool. \n",
    "review_best_ufc_RDD = review_RDD.map(lambda x : (x[2], (x[4], x[5], x[6]))).reduceByKey(lambda x, y : tuple(max(x[i], y[i]) for i in range(len(y))))\n",
    "\n",
    "# TODO split map and reduce\n",
    "review_best_ufc_RDD.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add map to turn the result in a simple tuple\n",
    "\n",
    "# (id_business, ((id_review, id_user, star, useful, funny , cool), (best useful, best funny, best cool)))\n",
    "review_ufc_RDD = review_RDD.map(lambda x: (x[2], (x[0], x[1], x[3], x[4], x[5], x[6]))).join(review_best_ufc_RDD)\n",
    "review_ufc_RDD.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add function / rewrite after map in previous cell\n",
    "\n",
    "partial_review_overall_RDD = review_ufc_RDD.map(lambda x: (x[1][0][0], x[1][0][1], x[0], x[1][0][2], \n",
    "                                                           (x[1][0][3] + (x[1][0][4] + x[1][0][5])/2) / (x[1][1][0] + (x[1][1][1] + x[1][1][2])/2) if sum(x[1][1]) != 0 else 0))\n",
    "partial_review_overall_RDD.first()\n",
    "\n",
    "# tuple: (review_id, user_id, buisness_id, stars, partial overall) \n",
    "\n",
    "# ('A2q7d-CBM2-81tVkmS4JMw',(('RB8UpF_kT2xoOC51OzXEeA', 'EZjT2qJN0mOXypMAqZdSrQ', 2, 1, 1, 0),(21, 13, 18)))\n",
    "\n",
    "#if(best_useful && best_funny && best_cool !=0 )\n",
    "# {[useful + (funny + cool)/2]/[best useful + (best funny + best cool)/2] + (numero fans/best user fans)}/2\n",
    "\n",
    "# x = 10 if sum(x[1][1]) != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple: (user_id, fans)\n",
    "user_fans_RDD = user_RDD.map(lambda x: (x[0], x[7]))\n",
    "\n",
    "# TODO add map to turn the result in a simple tuple\n",
    "# tuple: (user_id, (review_id, buisness_id, stars, partial overall), fans)\n",
    "partial_overall_fans_RDD = partial_review_overall_RDD.map(lambda x: (x[1], (x[0], x[2], x[3], x[4]))).join(user_fans_RDD)\n",
    "\n",
    "partial_overall_fans_RDD.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user with the highest number of fans\n",
    "best_user_fans = user_RDD.max(lambda x: x[7])\n",
    "print(best_user_fans)\n",
    "\n",
    "# TODO if best user fans = 0\n",
    "# TODO add function / rewrite after map in previous cell\n",
    "review_overall_RDD = partial_overall_fans_RDD.map(lambda x: (x[1][0][0], x[0], x[1][0][1], x[1][0][2] + (x[1][0][3]+x[1][1]/best_user_fans[7])/(2 if x[1][0][2] >=3 else -2)))\n",
    "\n",
    "review_overall_RDD.sortBy(lambda x:x[3], ascending=False).take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_RDD.sortBy(lambda x: x[5], ascending=False).take(10)\n",
    "\n",
    "# business_RDD.stats()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
